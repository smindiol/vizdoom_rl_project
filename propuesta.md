# Propuesta de Proyecto: Entrenamiento de un Agente RL Basado en Visi√≥n para ViZDoom - *Defend the Center*

## üéØ Objetivo General

Desarrollar un agente inteligente que aprenda a jugar el escenario **Defend the Center** de ViZDoom exclusivamente a partir de la informaci√≥n visual (frames del entorno), empleando aprendizaje por refuerzo profundo (Deep Reinforcement Learning, DRL). El enfoque se centra en simular un agente que toma decisiones √∫nicamente en base a lo que "ve", como lo har√≠a un humano, sin acceso a variables internas del entorno.

## üß† Enfoque T√©cnico

Se usar√° una red neuronal similar a DQN (*Deep Q-Network*) con posibles mejoras como atenci√≥n espacial. La entrada de la red ser√° una imagen preprocesada del entorno y la salida ser√° un conjunto discreto de acciones posibles.

## üõ† Herramientas y Tecnolog√≠as

- **ViZDoom**: Entorno de simulaci√≥n basado en Doom para tareas de RL.
- **PyTorch**: Framework de aprendizaje profundo usado para definir y entrenar las redes neuronales.
- **OpenCV y NumPy**: Procesamiento de im√°genes y manejo eficiente de datos.
- **Gym Interface**: Adaptaci√≥n del entorno ViZDoom a la interfaz de `gym` para facilitar el dise√±o de agentes.
- **Clase `GrayscaleProcessor` (procesamiento visual)**: M√≥dulo clave que encapsula el preprocesamiento visual.

---

## üëÅÔ∏è Procesamiento Visual

Una parte esencial del proyecto es la **transformaci√≥n de las im√°genes crudas del entorno** en representaciones √∫tiles para el agente. Aqu√≠ es donde entra la clase `GrayscaleProcessor`, la cual no solo convierte las im√°genes a escala de grises, sino que tambi√©n realiza:

- **Redimensionamiento de imagen**: Adaptaci√≥n a la forma esperada por la red (ej. 100x160 p√≠xeles).
- **Normalizaci√≥n**: Escalado de intensidades a valores entre 0 y 1.
- **Stacking de frames**: Apilamiento temporal de m√∫ltiples frames para capturar el movimiento (similar al marco de Atari DQN).
- **Ajustes opcionales** como detecci√≥n de contornos, mapas de calor, o simplificaci√≥n del canal de color.

Este enfoque modular permite f√°cilmente incorporar otras t√©cnicas de visi√≥n, como:

- Mapas de atenci√≥n (ej. saliency maps).
- Resaltado de enemigos con segmentaci√≥n sem√°ntica o etiquetas del entorno (si se usan).
- Canales auxiliares generados por modelos como YOLO (para detecci√≥n).

---

## ü§ñ Arquitectura del Agente

- **Red DQN o DQN con Atenci√≥n** (`DQNWithAttention`)
- **Entrada**: Imagen procesada (grayscale, shape `[C, H, W]`)
- **Salida**: Q-valores para cada acci√≥n posible.
- **Entrenamiento**:
  - Pol√≠tica Œµ-greedy.
  - Replay memory.
  - Target network.
  - Posible uso de priorizaci√≥n en el muestreo de experiencias.
